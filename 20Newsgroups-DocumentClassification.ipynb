{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Newsgroups - Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The various steps performed are:\n",
    "1. Data Exploration and Cleaning\n",
    "2. Data Transformation / Feature Extraction\n",
    "3. Modeling\n",
    "4. Training and testing results of the models\n",
    "5. Comparative analysis of accuracy to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in /anaconda3/lib/python3.7/site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from langid) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langid\n",
    "#Importing Necessary Libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training and test dataset\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state = 50)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints all the categories that are present in the dataset\n",
    "# There are 20 categories of news\n",
    "newsgroups_train.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: twork@egr.msu.edu (Michael Twork)\n",
      "Subject: Re: Thumbs up to ESPN\n",
      "Organization: Michigan State University\n"
     ]
    }
   ],
   "source": [
    "#prints first line of the first data file\n",
    "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[:3])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Remove Non Ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_non_ascii(data_str):\n",
    "    ''' Returns the string without non ASCII characters''' \n",
    "    stripped = (c for c in data_str if 0 < ord(c) < 127) \n",
    "    return ''.join(stripped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Clean the corpus by removing unwanted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(data_str): # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?') \n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation)) \n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    mention_re = re.compile('@(\\w+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove @mentions\n",
    "    data_str = mention_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 1 characters \n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = word \n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = cleaned_str + ' ' + word \n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    \n",
    "    return \" \".join(cleaned_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Perform Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(data_str):\n",
    "    # expects a string\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    lmtzr = WordNetLemmatizer() \n",
    "    text = data_str.split() \n",
    "    tagged_words = pos_tag(text) \n",
    "    for word in tagged_words:\n",
    "        if 'v' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='v')\n",
    "        else:\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='n')\n",
    "        if list_pos == 0: \n",
    "            cleaned_str = lemma\n",
    "        else:\n",
    "            cleaned_str = cleaned_str + ' ' + lemma\n",
    "        list_pos += 1 \n",
    "    return cleaned_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean train and test data by applying the fuctions created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Train Data\n",
    "train_clean = []\n",
    "for i in range(len(newsgroups_train.data)):\n",
    "    res = remove_features(newsgroups_train.data[i])\n",
    "    res1 = strip_non_ascii(res)\n",
    "    res2 = lemmatize(res1)\n",
    "    train_clean.append(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Test Data\n",
    "test_clean = []\n",
    "for i in range(len(newsgroups_test.data)):\n",
    "    res = remove_features(newsgroups_test.data[i])\n",
    "    res1 = strip_non_ascii(res)\n",
    "    res2 = lemmatize(res1)\n",
    "    test_clean.append(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.08185201,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a TFIDF vectorizer\n",
    "tv = TfidfVectorizer(stop_words=\"english\",min_df = 0.01, max_df = 0.85)\n",
    "train_tv = tv.fit_transform(train_clean).todense()\n",
    "test_tv = tv.transform(test_clean)\n",
    "train_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the vector to dataframe\n",
    "dt = pd.DataFrame(train_tv,columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>ac</th>\n",
       "      <th>academic</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>writes</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1707 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa   ab  ability      able  absolute  absolutely  abuse   ac  academic  \\\n",
       "0  0.0  0.0      0.0  0.000000       0.0         0.0    0.0  0.0       0.0   \n",
       "1  0.0  0.0      0.0  0.101277       0.0         0.0    0.0  0.0       0.0   \n",
       "2  0.0  0.0      0.0  0.000000       0.0         0.0    0.0  0.0       0.0   \n",
       "3  0.0  0.0      0.0  0.000000       0.0         0.0    0.0  0.0       0.0   \n",
       "4  0.0  0.0      0.0  0.000000       0.0         0.0    0.0  0.0       0.0   \n",
       "\n",
       "   accept  ...   writer  writes  wrong  yeah     year  yes  yesterday  york  \\\n",
       "0     0.0  ...      0.0     0.0    0.0   0.0  0.00000  0.0        0.0   0.0   \n",
       "1     0.0  ...      0.0     0.0    0.0   0.0  0.00000  0.0        0.0   0.0   \n",
       "2     0.0  ...      0.0     0.0    0.0   0.0  0.00000  0.0        0.0   0.0   \n",
       "3     0.0  ...      0.0     0.0    0.0   0.0  0.00000  0.0        0.0   0.0   \n",
       "4     0.0  ...      0.0     0.0    0.0   0.0  0.42459  0.0        0.0   0.0   \n",
       "\n",
       "   young  zero  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "\n",
       "[5 rows x 1707 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Document term matrix using Count Vectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\", min_df = 0.01, max_df = 0.9)\n",
    "train_cv = cv.fit_transform(train_clean)\n",
    "test_cv = cv.transform(test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Modeling :\n",
    "    1. Naive Bayes\n",
    "    2. SGD Classifier\n",
    "    3. Support Vector Machines\n",
    "    4. Random Forest\n",
    "    5. Logistic Regression\n",
    "    6. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Naive Bayes using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes using TFIDF\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB(alpha=0.1))])\n",
    "\n",
    "text_clf.fit(train_clean, newsgroups_train.target)  \n",
    "\n",
    "pred_test = text_clf.predict(test_clean)\n",
    "pred_train = text_clf.predict(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Naive Bayes Accuracy Score ->  98.18808555771611\n",
      "train data: Naive Bayes precision Score ->  98.28757106016826\n",
      "train data: Naive Bayes recall Score ->  97.78470301504868\n",
      "train data: Naive Bayes f1 Score ->  97.93053518942601\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"train data: Naive Bayes Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: Naive Bayes precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Naive Bayes recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Naive Bayes f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: Naive Bayes Accuracy Score ->  82.58098778544876\n",
      "Test data: Naive Bayes precision Score ->  83.7520034786151\n",
      "Test data: Naive Bayes recall Score ->  81.36526403917198\n",
      "Test data: Naive Bayes f1 Score ->  81.3218215415369\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for test data\n",
    "print(\"Test data: Naive Bayes Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"Test data: Naive Bayes precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Naive Bayes recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Naive Bayes f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.73      0.78       319\n",
      "           comp.graphics       0.76      0.75      0.75       389\n",
      " comp.os.ms-windows.misc       0.77      0.64      0.70       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.83      0.84      0.84       385\n",
      "          comp.windows.x       0.86      0.79      0.83       395\n",
      "            misc.forsale       0.90      0.72      0.80       390\n",
      "               rec.autos       0.88      0.91      0.90       396\n",
      "         rec.motorcycles       0.90      0.97      0.93       398\n",
      "      rec.sport.baseball       0.94      0.95      0.95       397\n",
      "        rec.sport.hockey       0.95      0.97      0.96       399\n",
      "               sci.crypt       0.80      0.95      0.87       396\n",
      "         sci.electronics       0.79      0.75      0.77       393\n",
      "                 sci.med       0.90      0.85      0.88       396\n",
      "               sci.space       0.87      0.92      0.89       394\n",
      "  soc.religion.christian       0.68      0.96      0.80       398\n",
      "      talk.politics.guns       0.67      0.95      0.79       364\n",
      "   talk.politics.mideast       0.94      0.95      0.95       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.91      0.35      0.51       251\n",
      "\n",
      "               micro avg       0.83      0.83      0.83      7532\n",
      "               macro avg       0.84      0.81      0.81      7532\n",
      "            weighted avg       0.84      0.83      0.82      7532\n",
      "\n",
      "Accuracy of the model= 0.8258098778544876\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Naive Bayes using countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "clf2 = MultinomialNB(alpha=.01)\n",
    "clf2.fit(train_cv, newsgroups_train.target)\n",
    "pred_test = clf2.predict(test_cv)\n",
    "pred_train = clf2.predict(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Naive Bayes Accuracy Score ->  85.0715927169878\n",
      "train data: Naive Bayes precision Score ->  85.5164254833315\n",
      "train data: Naive Bayes recall Score ->  84.99201621489777\n",
      "train data: Naive Bayes f1 Score ->  84.98016685058315\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"train data: Naive Bayes Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: Naive Bayes precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Naive Bayes recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Naive Bayes f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: Naive Bayes Accuracy Score ->  70.06107275624004\n",
      "Test data: Naive Bayes precision Score ->  70.27762853143636\n",
      "Test data: Naive Bayes recall Score ->  69.38217556149547\n",
      "Test data: Naive Bayes f1 Score ->  69.07111685825271\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"Test data: Naive Bayes Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"Test data: Naive Bayes precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Naive Bayes recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Naive Bayes f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.66      0.67      0.66       319\n",
      "           comp.graphics       0.51      0.68      0.58       389\n",
      " comp.os.ms-windows.misc       0.67      0.27      0.38       394\n",
      "comp.sys.ibm.pc.hardware       0.53      0.58      0.55       392\n",
      "   comp.sys.mac.hardware       0.58      0.67      0.62       385\n",
      "          comp.windows.x       0.71      0.65      0.68       395\n",
      "            misc.forsale       0.71      0.79      0.75       390\n",
      "               rec.autos       0.70      0.76      0.73       396\n",
      "         rec.motorcycles       0.70      0.88      0.78       398\n",
      "      rec.sport.baseball       0.86      0.83      0.85       397\n",
      "        rec.sport.hockey       0.91      0.88      0.90       399\n",
      "               sci.crypt       0.88      0.81      0.84       396\n",
      "         sci.electronics       0.59      0.61      0.60       393\n",
      "                 sci.med       0.76      0.68      0.72       396\n",
      "               sci.space       0.79      0.81      0.80       394\n",
      "  soc.religion.christian       0.82      0.82      0.82       398\n",
      "      talk.politics.guns       0.62      0.78      0.70       364\n",
      "   talk.politics.mideast       0.96      0.77      0.86       376\n",
      "      talk.politics.misc       0.59      0.45      0.51       310\n",
      "      talk.religion.misc       0.49      0.49      0.49       251\n",
      "\n",
      "               micro avg       0.70      0.70      0.70      7532\n",
      "               macro avg       0.70      0.69      0.69      7532\n",
      "            weighted avg       0.71      0.70      0.70      7532\n",
      "\n",
      "Accuracy of the model= 0.7006107275624004\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 SGD classifier using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "alpha=1e-3, random_state=42,max_iter=5, tol=0.0001))])\n",
    "\n",
    "text_clf.fit(train_clean, newsgroups_train.target)  \n",
    "\n",
    "pred_test = text_clf.predict(test_clean)\n",
    "pred_train = text_clf.predict(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: SGD Accuracy Score ->  95.62488951741206\n",
      "train data: SGD precision Score ->  95.83029676163434\n",
      "train data: SGD recall Score ->  95.04553312471998\n",
      "train data: SGD f1 Score ->  95.22550933150444\n"
     ]
    }
   ],
   "source": [
    "print(\"train data: SGD Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: SGD precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SGD recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SGD f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: SGD Accuracy Score ->  81.82421667551779\n",
      "test data: SGD precision Score ->  82.38162486647323\n",
      "test data: SGD recall Score ->  80.66383171630622\n",
      "test data: SGD f1 Score ->  80.50730381817907\n"
     ]
    }
   ],
   "source": [
    "print(\"test data: SGD Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"test data: SGD precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SGD recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SGD f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.71      0.69      0.70       319\n",
      "           comp.graphics       0.79      0.73      0.76       389\n",
      " comp.os.ms-windows.misc       0.75      0.70      0.72       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.69      0.71       392\n",
      "   comp.sys.mac.hardware       0.80      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.75      0.79       395\n",
      "            misc.forsale       0.82      0.86      0.84       390\n",
      "               rec.autos       0.89      0.88      0.88       396\n",
      "         rec.motorcycles       0.91      0.95      0.93       398\n",
      "      rec.sport.baseball       0.90      0.91      0.90       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.82      0.96      0.88       396\n",
      "         sci.electronics       0.83      0.65      0.73       393\n",
      "                 sci.med       0.89      0.86      0.88       396\n",
      "               sci.space       0.83      0.95      0.89       394\n",
      "  soc.religion.christian       0.73      0.93      0.82       398\n",
      "      talk.politics.guns       0.67      0.94      0.78       364\n",
      "   talk.politics.mideast       0.90      0.92      0.91       376\n",
      "      talk.politics.misc       0.91      0.55      0.69       310\n",
      "      talk.religion.misc       0.86      0.38      0.53       251\n",
      "\n",
      "               micro avg       0.82      0.82      0.82      7532\n",
      "               macro avg       0.82      0.81      0.81      7532\n",
      "            weighted avg       0.82      0.82      0.81      7532\n",
      "\n",
      "Accuracy of the model= 0.8182421667551779\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 SGD classifier using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=0.0001)\n",
    "clf.fit(train_cv, newsgroups_train.target)\n",
    "pred_train1 = clf.predict(train_cv)\n",
    "pred_test = clf.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: SGD Accuracy Score ->  92.9998232278593\n",
      "train data: SGD precision Score ->  93.32875462519206\n",
      "train data: SGD recall Score ->  93.08295060265847\n",
      "train data: SGD f1 Score ->  93.09501077340695\n"
     ]
    }
   ],
   "source": [
    "print(\"train data: SGD Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train1)*100)\n",
    "print(\"train data: SGD precision Score -> \",precision_score(newsgroups_train.target, pred_train1,average='macro')*100)\n",
    "print(\"train data: SGD recall Score -> \",recall_score(newsgroups_train.target, pred_train1,average='macro')*100)\n",
    "print(\"train data: SGD f1 Score -> \",f1_score(newsgroups_train.target, pred_train1, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: SGD Accuracy Score ->  68.73340414232607\n",
      "test data: SGD precision Score ->  69.1596266654847\n",
      "test data: SGD recall Score ->  67.9838431570855\n",
      "test data: SGD f1 Score ->  67.85005965681187\n"
     ]
    }
   ],
   "source": [
    "print(\"test data: SGD Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"test data: SGD precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SGD recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SGD f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.51      0.65      0.57       319\n",
      "           comp.graphics       0.61      0.54      0.57       389\n",
      " comp.os.ms-windows.misc       0.65      0.49      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.53      0.59      0.56       392\n",
      "   comp.sys.mac.hardware       0.51      0.79      0.62       385\n",
      "          comp.windows.x       0.62      0.70      0.66       395\n",
      "            misc.forsale       0.73      0.75      0.74       390\n",
      "               rec.autos       0.77      0.74      0.76       396\n",
      "         rec.motorcycles       0.82      0.83      0.82       398\n",
      "      rec.sport.baseball       0.83      0.76      0.80       397\n",
      "        rec.sport.hockey       0.86      0.90      0.88       399\n",
      "               sci.crypt       0.79      0.84      0.81       396\n",
      "         sci.electronics       0.69      0.44      0.54       393\n",
      "                 sci.med       0.80      0.63      0.70       396\n",
      "               sci.space       0.86      0.78      0.82       394\n",
      "  soc.religion.christian       0.77      0.77      0.77       398\n",
      "      talk.politics.guns       0.59      0.81      0.68       364\n",
      "   talk.politics.mideast       0.84      0.72      0.78       376\n",
      "      talk.politics.misc       0.65      0.44      0.52       310\n",
      "      talk.religion.misc       0.39      0.43      0.41       251\n",
      "\n",
      "               micro avg       0.69      0.69      0.69      7532\n",
      "               macro avg       0.69      0.68      0.68      7532\n",
      "            weighted avg       0.70      0.69      0.69      7532\n",
      "\n",
      "Accuracy of the model= 0.6873340414232607\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Support Vector Machines using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.08185201,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a TFIDF vectorizer\n",
    "tv = TfidfVectorizer(stop_words=\"english\",min_df = 0.01, max_df = 0.95)\n",
    "train_tv1 = tv.fit_transform(train_clean).todense()\n",
    "test_tv1 = tv.transform(test_clean).todense()\n",
    "train_tv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running SVM for TFIDF\n",
    "svclassifier = SVC(kernel='linear', C=0.1, gamma = 0.1)  \n",
    "svclassifier.fit(train_tv1, newsgroups_train.target)\n",
    "pred_train = svclassifier.predict(train_tv1)\n",
    "pred_test = svclassifier.predict(test_tv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: SVM Accuracy Score ->  80.91744741028813\n",
      "train data: SVM precision Score ->  83.68017415239343\n",
      "train data: SVM recall Score ->  79.9555309571556\n",
      "train data: SVM f1 Score ->  80.42712364571578\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"train data: SVM Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: SVM precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SVM recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SVM f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: SVM Accuracy Score ->  69.06532129580457\n",
      "test data: SVM precision Score ->  72.8444291707015\n",
      "test data: SVM recall Score ->  67.74937145779408\n",
      "test data: SVM f1 Score ->  68.35824909958883\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for test data\n",
    "print(\"test data: SVM Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"test data: SVM precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SVM recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SVM f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.64      0.53      0.58       319\n",
      "           comp.graphics       0.58      0.69      0.63       389\n",
      " comp.os.ms-windows.misc       0.69      0.63      0.66       394\n",
      "comp.sys.ibm.pc.hardware       0.61      0.61      0.61       392\n",
      "   comp.sys.mac.hardware       0.74      0.63      0.68       385\n",
      "          comp.windows.x       0.74      0.62      0.67       395\n",
      "            misc.forsale       0.79      0.73      0.76       390\n",
      "               rec.autos       0.82      0.72      0.76       396\n",
      "         rec.motorcycles       0.87      0.81      0.84       398\n",
      "      rec.sport.baseball       0.78      0.86      0.82       397\n",
      "        rec.sport.hockey       0.93      0.85      0.89       399\n",
      "               sci.crypt       0.96      0.69      0.80       396\n",
      "         sci.electronics       0.34      0.78      0.47       393\n",
      "                 sci.med       0.67      0.67      0.67       396\n",
      "               sci.space       0.85      0.79      0.82       394\n",
      "  soc.religion.christian       0.67      0.87      0.76       398\n",
      "      talk.politics.guns       0.65      0.74      0.69       364\n",
      "   talk.politics.mideast       0.98      0.65      0.78       376\n",
      "      talk.politics.misc       0.49      0.53      0.51       310\n",
      "      talk.religion.misc       0.77      0.16      0.27       251\n",
      "\n",
      "               micro avg       0.69      0.69      0.69      7532\n",
      "               macro avg       0.73      0.68      0.68      7532\n",
      "            weighted avg       0.73      0.69      0.69      7532\n",
      "\n",
      "Accuracy of the model= 0.6906532129580457\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 SVM using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running SVM for Count Vectorizer\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=0.1, gamma = 0.1)  \n",
    "svclassifier.fit(train_cv, newsgroups_train.target)\n",
    "pred_train = svclassifier.predict(train_cv)\n",
    "pred_test = svclassifier.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: SVM Accuracy Score ->  99.14265511755347\n",
      "train data: SVM precision Score ->  99.18173502939864\n",
      "train data: SVM recall Score ->  99.15841647412218\n",
      "train data: SVM f1 Score ->  99.1682722202168\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"train data: SVM Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: SVM precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SVM recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: SVM f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: SVM Accuracy Score ->  67.55177907594265\n",
      "test data: SVM precision Score ->  67.38747865113191\n",
      "test data: SVM recall Score ->  66.77518016376872\n",
      "test data: SVM f1 Score ->  66.78307179022993\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"test data: SVM Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"test data: SVM precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SVM recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: SVM f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.65      0.58       319\n",
      "           comp.graphics       0.49      0.63      0.55       389\n",
      " comp.os.ms-windows.misc       0.63      0.57      0.60       394\n",
      "comp.sys.ibm.pc.hardware       0.57      0.58      0.58       392\n",
      "   comp.sys.mac.hardware       0.59      0.65      0.62       385\n",
      "          comp.windows.x       0.69      0.62      0.65       395\n",
      "            misc.forsale       0.73      0.78      0.76       390\n",
      "               rec.autos       0.70      0.70      0.70       396\n",
      "         rec.motorcycles       0.84      0.81      0.82       398\n",
      "      rec.sport.baseball       0.72      0.77      0.75       397\n",
      "        rec.sport.hockey       0.88      0.84      0.86       399\n",
      "               sci.crypt       0.80      0.79      0.79       396\n",
      "         sci.electronics       0.56      0.52      0.54       393\n",
      "                 sci.med       0.71      0.58      0.64       396\n",
      "               sci.space       0.80      0.80      0.80       394\n",
      "  soc.religion.christian       0.80      0.81      0.80       398\n",
      "      talk.politics.guns       0.59      0.76      0.66       364\n",
      "   talk.politics.mideast       0.86      0.67      0.75       376\n",
      "      talk.politics.misc       0.52      0.40      0.45       310\n",
      "      talk.religion.misc       0.47      0.43      0.44       251\n",
      "\n",
      "               micro avg       0.68      0.68      0.68      7532\n",
      "               macro avg       0.67      0.67      0.67      7532\n",
      "            weighted avg       0.68      0.68      0.68      7532\n",
      "\n",
      "Accuracy of the model= 0.6755177907594264\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 RandomForest Classifier using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', RandomForestClassifier(n_estimators=500,criterion='entropy',random_state=0,max_depth=20, min_impurity_decrease=0.001))])\n",
    "\n",
    "text_clf.fit(train_clean, newsgroups_train.target)  \n",
    "\n",
    "pred_test = text_clf.predict(test_clean)\n",
    "pred_train = text_clf.predict(train_clean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Random Forest Accuracy Score ->  89.64999116139296\n",
      "train data: Random Forest precision Score ->  91.9691029577696\n",
      "train data: Random Forest recall Score ->  88.77855109333403\n",
      "train data: Random Forest f1 Score ->  89.35801510035198\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for train data\n",
    "print(\"train data: Random Forest Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: Random Forest precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Random Forest recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Random Forest f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: Random Forest Accuracy Score ->  69.87519915029209\n",
      "Test data: Random Forest precision Score ->  74.9423068244963\n",
      "Test data: Random Forest recall Score ->  68.1724575196023\n",
      "Test data: Random Forest f1 Score ->  67.35790305785214\n"
     ]
    }
   ],
   "source": [
    "# # Performance Metrics for test data\n",
    "print(\"Test data: Random Forest Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"Test data: Random Forest precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Random Forest recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"Test data: Random Forest f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.48      0.57       319\n",
      "           comp.graphics       0.58      0.61      0.59       389\n",
      " comp.os.ms-windows.misc       0.62      0.68      0.65       394\n",
      "comp.sys.ibm.pc.hardware       0.64      0.61      0.62       392\n",
      "   comp.sys.mac.hardware       0.80      0.67      0.73       385\n",
      "          comp.windows.x       0.70      0.67      0.68       395\n",
      "            misc.forsale       0.45      0.94      0.61       390\n",
      "               rec.autos       0.83      0.73      0.78       396\n",
      "         rec.motorcycles       0.83      0.86      0.85       398\n",
      "      rec.sport.baseball       0.83      0.81      0.82       397\n",
      "        rec.sport.hockey       0.83      0.93      0.88       399\n",
      "               sci.crypt       0.81      0.89      0.85       396\n",
      "         sci.electronics       0.73      0.40      0.51       393\n",
      "                 sci.med       0.85      0.56      0.67       396\n",
      "               sci.space       0.81      0.84      0.82       394\n",
      "  soc.religion.christian       0.52      0.90      0.66       398\n",
      "      talk.politics.guns       0.59      0.84      0.69       364\n",
      "   talk.politics.mideast       0.90      0.80      0.85       376\n",
      "      talk.politics.misc       0.95      0.38      0.54       310\n",
      "      talk.religion.misc       1.00      0.05      0.09       251\n",
      "\n",
      "               micro avg       0.70      0.70      0.70      7532\n",
      "               macro avg       0.75      0.68      0.67      7532\n",
      "            weighted avg       0.74      0.70      0.69      7532\n",
      "\n",
      "Accuracy of the model= 0.6987519915029209\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 RandomfForest classifier using countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=RandomForestClassifier(n_estimators=500,criterion='entropy',random_state=0,max_depth=20, min_impurity_decrease=0.001)\n",
    "clf2.fit(train_cv, newsgroups_train.target)\n",
    "pred_train2 = clf2.predict(train_cv)\n",
    "pred_test2 = clf2.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Random Forest Accuracy Score ->  81.51847268870426\n",
      "train data: Random Forest precision Score ->  83.2006089258025\n",
      "train data: Random Forest recall Score ->  80.84915598285883\n",
      "train data: Random Forest f1 Score ->  81.33508701152319\n"
     ]
    }
   ],
   "source": [
    "print(\"train data: Random Forest Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train2)*100)\n",
    "print(\"train data: Random Forest precision Score -> \",precision_score(newsgroups_train.target, pred_train2,average='macro')*100)\n",
    "print(\"train data: Random Forest recall Score -> \",recall_score(newsgroups_train.target, pred_train2,average='macro')*100)\n",
    "print(\"train data: Random Forest f1 Score -> \",f1_score(newsgroups_train.target, pred_train2, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: Random Forest Accuracy Score ->  65.06903876792353\n",
      "Test data: Random Forest precision Score ->  66.44049573687066\n",
      "Test data: Random Forest recall Score ->  63.75034501522342\n",
      "Test data: Random Forest f1 Score ->  63.651407039617226\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data: Random Forest Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test2)*100)\n",
    "print(\"Test data: Random Forest precision Score -> \",precision_score(newsgroups_test.target, pred_test2,average='macro')*100)\n",
    "print(\"Test data: Random Forest recall Score -> \",recall_score(newsgroups_test.target, pred_test2,average='macro')*100)\n",
    "print(\"Test data: Random Forest f1 Score -> \",f1_score(newsgroups_test.target, pred_test2, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.66      0.49      0.56       319\n",
      "           comp.graphics       0.52      0.58      0.55       389\n",
      " comp.os.ms-windows.misc       0.54      0.67      0.60       394\n",
      "comp.sys.ibm.pc.hardware       0.54      0.55      0.54       392\n",
      "   comp.sys.mac.hardware       0.72      0.61      0.66       385\n",
      "          comp.windows.x       0.68      0.48      0.56       395\n",
      "            misc.forsale       0.66      0.79      0.72       390\n",
      "               rec.autos       0.76      0.66      0.71       396\n",
      "         rec.motorcycles       0.88      0.81      0.84       398\n",
      "      rec.sport.baseball       0.78      0.74      0.76       397\n",
      "        rec.sport.hockey       0.83      0.86      0.85       399\n",
      "               sci.crypt       0.84      0.83      0.84       396\n",
      "         sci.electronics       0.34      0.39      0.36       393\n",
      "                 sci.med       0.47      0.63      0.54       396\n",
      "               sci.space       0.70      0.76      0.73       394\n",
      "  soc.religion.christian       0.61      0.89      0.72       398\n",
      "      talk.politics.guns       0.57      0.75      0.65       364\n",
      "   talk.politics.mideast       0.92      0.73      0.82       376\n",
      "      talk.politics.misc       0.57      0.32      0.41       310\n",
      "      talk.religion.misc       0.68      0.20      0.31       251\n",
      "\n",
      "               micro avg       0.65      0.65      0.65      7532\n",
      "               macro avg       0.66      0.64      0.64      7532\n",
      "            weighted avg       0.67      0.65      0.65      7532\n",
      "\n",
      "Accuracy of the model= 0.6506903876792353\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test2, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Logistic Regression using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression())])\n",
    "\n",
    "text_clf.fit(train_clean, newsgroups_train.target)  \n",
    "\n",
    "pred_test = text_clf.predict(test_clean)\n",
    "pred_train = text_clf.predict(train_clean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Logistic Regression Accuracy Score ->  96.47339579282304\n",
      "train data: Logistic Regression precision Score ->  96.60419387727973\n",
      "train data: Logistic Regression recall Score ->  96.21266996821467\n",
      "train data: Logistic Regression f1 Score ->  96.35813188687166\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"train data: Logistic Regression Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train)*100)\n",
    "print(\"train data: Logistic Regression precision Score -> \",precision_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Logistic Regression recall Score -> \",recall_score(newsgroups_train.target, pred_train,average='macro')*100)\n",
    "print(\"train data: Logistic Regression f1 Score -> \",f1_score(newsgroups_train.target, pred_train, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: Logistic Regression Accuracy Score ->  82.14285714285714\n",
      "test data: Logistic Regression precision Score ->  82.31316449560545\n",
      "test data: Logistic Regression recall Score ->  81.13012352679375\n",
      "test data: Logistic Regression f1 Score ->  81.24197622183736\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"test data: Logistic Regression Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test)*100)\n",
    "print(\"test data: Logistic Regression precision Score -> \",precision_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: Logistic Regression recall Score -> \",recall_score(newsgroups_test.target, pred_test,average='macro')*100)\n",
    "print(\"test data: Logistic Regression f1 Score -> \",f1_score(newsgroups_test.target, pred_test, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.71      0.74       319\n",
      "           comp.graphics       0.70      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.73      0.71      0.72       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.82      0.82      0.82       385\n",
      "          comp.windows.x       0.81      0.74      0.77       395\n",
      "            misc.forsale       0.74      0.86      0.80       390\n",
      "               rec.autos       0.90      0.87      0.89       396\n",
      "         rec.motorcycles       0.95      0.94      0.94       398\n",
      "      rec.sport.baseball       0.90      0.93      0.91       397\n",
      "        rec.sport.hockey       0.95      0.96      0.95       399\n",
      "               sci.crypt       0.92      0.89      0.91       396\n",
      "         sci.electronics       0.74      0.78      0.76       393\n",
      "                 sci.med       0.87      0.86      0.86       396\n",
      "               sci.space       0.88      0.92      0.90       394\n",
      "  soc.religion.christian       0.77      0.92      0.84       398\n",
      "      talk.politics.guns       0.73      0.89      0.80       364\n",
      "   talk.politics.mideast       0.96      0.87      0.92       376\n",
      "      talk.politics.misc       0.77      0.61      0.68       310\n",
      "      talk.religion.misc       0.82      0.44      0.58       251\n",
      "\n",
      "               micro avg       0.82      0.82      0.82      7532\n",
      "               macro avg       0.82      0.81      0.81      7532\n",
      "            weighted avg       0.82      0.82      0.82      7532\n",
      "\n",
      "Accuracy of the model= 0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Logistic Regression using countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(train_cv, newsgroups_train.target)\n",
    "\n",
    "pred_train2= lr.predict(train_cv)\n",
    "pred_test2 = lr.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Logistic Regression Accuracy Score ->  99.34594307937068\n",
      "train data: Logistic Regression precision Score ->  99.37330439916387\n",
      "train data: Logistic Regression recall Score ->  99.35920962531006\n",
      "train data: Logistic Regression f1 Score ->  99.36513975002069\n"
     ]
    }
   ],
   "source": [
    "print(\"train data: Logistic Regression Accuracy Score -> \",accuracy_score(newsgroups_train.target, pred_train2)*100)\n",
    "print(\"train data: Logistic Regression precision Score -> \",precision_score(newsgroups_train.target, pred_train2,average='macro')*100)\n",
    "print(\"train data: Logistic Regression recall Score -> \",recall_score(newsgroups_train.target, pred_train2,average='macro')*100)\n",
    "print(\"train data: Logistic Regression f1 Score -> \",f1_score(newsgroups_train.target, pred_train2, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: Logistic Regression Accuracy Score ->  70.06107275624004\n",
      "test data: Logistic Regression precision Score ->  69.77587967499662\n",
      "test data: Logistic Regression recall Score ->  69.21498840566878\n",
      "test data: Logistic Regression f1 Score ->  69.3242005120084\n"
     ]
    }
   ],
   "source": [
    "print(\"test data: Logistic Regression Accuracy Score -> \",accuracy_score(newsgroups_test.target, pred_test2)*100)\n",
    "print(\"test data: Logistic Regression precision Score -> \",precision_score(newsgroups_test.target, pred_test2,average='macro')*100)\n",
    "print(\"test data: Logistic Regression recall Score -> \",recall_score(newsgroups_test.target, pred_test2,average='macro')*100)\n",
    "print(\"test data: Logistic Regression f1 Score -> \",f1_score(newsgroups_test.target, pred_test2, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.60      0.63      0.62       319\n",
      "           comp.graphics       0.57      0.59      0.58       389\n",
      " comp.os.ms-windows.misc       0.62      0.59      0.61       394\n",
      "comp.sys.ibm.pc.hardware       0.53      0.60      0.56       392\n",
      "   comp.sys.mac.hardware       0.60      0.71      0.65       385\n",
      "          comp.windows.x       0.67      0.64      0.65       395\n",
      "            misc.forsale       0.76      0.78      0.77       390\n",
      "               rec.autos       0.74      0.77      0.75       396\n",
      "         rec.motorcycles       0.85      0.82      0.84       398\n",
      "      rec.sport.baseball       0.78      0.81      0.79       397\n",
      "        rec.sport.hockey       0.91      0.88      0.89       399\n",
      "               sci.crypt       0.88      0.81      0.84       396\n",
      "         sci.electronics       0.58      0.59      0.58       393\n",
      "                 sci.med       0.76      0.68      0.72       396\n",
      "               sci.space       0.84      0.82      0.83       394\n",
      "  soc.religion.christian       0.76      0.80      0.78       398\n",
      "      talk.politics.guns       0.66      0.76      0.71       364\n",
      "   talk.politics.mideast       0.90      0.71      0.79       376\n",
      "      talk.politics.misc       0.55      0.45      0.49       310\n",
      "      talk.religion.misc       0.40      0.43      0.41       251\n",
      "\n",
      "               micro avg       0.70      0.70      0.70      7532\n",
      "               macro avg       0.70      0.69      0.69      7532\n",
      "            weighted avg       0.71      0.70      0.70      7532\n",
      "\n",
      "Accuracy of the model= 0.7006107275624004\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, pred_test2, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, pred_test2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Decision Tree using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=50, splitter = 'random',min_samples_split=2, max_leaf_nodes = 80)\n",
    "clf_entropy.fit(train_tv, newsgroups_train.target)\n",
    "test_pred = clf_entropy.predict(test_tv)\n",
    "train_pred = clf_entropy.predict(train_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Decision Tree Accuracy Score ->  48.96588297684285\n",
      "train data: Decision Tree precision Score ->  53.43252484761276\n",
      "train data: Decision Tree recall Score ->  47.59761747978876\n",
      "train data: Decision Tree f1 Score ->  47.96333061113469\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"train data: Decision Tree Accuracy Score -> \",accuracy_score(newsgroups_train.target, train_pred)*100)\n",
    "print(\"train data: Decision Tree precision Score -> \",precision_score(newsgroups_train.target, train_pred,average='macro')*100)\n",
    "print(\"train data: Decision Tree recall Score -> \",recall_score(newsgroups_train.target, train_pred,average='macro')*100)\n",
    "print(\"train data: Decision Tree f1 Score -> \",f1_score(newsgroups_train.target, train_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: Decision Tree Accuracy Score ->  42.84386617100372\n",
      "test data: Decision Tree precision Score ->  46.997319918575485\n",
      "test data: Decision Tree recall Score ->  41.430644216646115\n",
      "test data: Decision Tree f1 Score ->  41.89742138923517\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"test data: Decision Tree Accuracy Score -> \",accuracy_score(newsgroups_test.target, test_pred)*100)\n",
    "print(\"test data: Decision Tree precision Score -> \",precision_score(newsgroups_test.target, test_pred,average='macro')*100)\n",
    "print(\"test data: Decision Tree recall Score -> \",recall_score(newsgroups_test.target, test_pred,average='macro')*100)\n",
    "print(\"test data: Decision Tree f1 Score -> \",f1_score(newsgroups_test.target, test_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.31      0.12      0.17       319\n",
      "           comp.graphics       0.48      0.38      0.42       389\n",
      " comp.os.ms-windows.misc       0.56      0.56      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.42      0.34      0.38       392\n",
      "   comp.sys.mac.hardware       0.61      0.47      0.53       385\n",
      "          comp.windows.x       0.15      0.28      0.20       395\n",
      "            misc.forsale       0.73      0.48      0.58       390\n",
      "               rec.autos       0.71      0.58      0.64       396\n",
      "         rec.motorcycles       0.88      0.66      0.76       398\n",
      "      rec.sport.baseball       0.27      0.37      0.31       397\n",
      "        rec.sport.hockey       0.48      0.67      0.56       399\n",
      "               sci.crypt       0.77      0.58      0.66       396\n",
      "         sci.electronics       0.25      0.15      0.19       393\n",
      "                 sci.med       0.16      0.33      0.22       396\n",
      "               sci.space       0.68      0.47      0.56       394\n",
      "  soc.religion.christian       0.33      0.80      0.47       398\n",
      "      talk.politics.guns       0.37      0.46      0.41       364\n",
      "   talk.politics.mideast       0.86      0.46      0.60       376\n",
      "      talk.politics.misc       0.21      0.10      0.14       310\n",
      "      talk.religion.misc       0.17      0.02      0.04       251\n",
      "\n",
      "               micro avg       0.43      0.43      0.43      7532\n",
      "               macro avg       0.47      0.41      0.42      7532\n",
      "            weighted avg       0.48      0.43      0.43      7532\n",
      "\n",
      "Accuracy of the model= 0.4284386617100372\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, test_pred, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, test_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Decision Tree using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=50, splitter = 'random',min_samples_split=2, max_leaf_nodes = 80)\n",
    "clf_entropy.fit(train_cv, newsgroups_train.target)\n",
    "test_pred = clf_entropy.predict(test_cv)\n",
    "train_pred = clf_entropy.predict(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Decision Tree Accuracy Score ->  48.70072476577691\n",
      "train data: Decision Tree precision Score ->  56.74709217035879\n",
      "train data: Decision Tree recall Score ->  47.669401744842524\n",
      "train data: Decision Tree f1 Score ->  48.68271828829475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"train data: Decision Tree Accuracy Score -> \",accuracy_score(newsgroups_train.target, train_pred)*100)\n",
    "print(\"train data: Decision Tree precision Score -> \",precision_score(newsgroups_train.target, train_pred,average='macro')*100)\n",
    "print(\"train data: Decision Tree recall Score -> \",recall_score(newsgroups_train.target, train_pred,average='macro')*100)\n",
    "print(\"train data: Decision Tree f1 Score -> \",f1_score(newsgroups_train.target, train_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: Decision Tree Accuracy Score ->  42.43228890069039\n",
      "test data: Decision Tree precision Score ->  50.99974857518886\n",
      "test data: Decision Tree recall Score ->  41.275111269473335\n",
      "test data: Decision Tree f1 Score ->  42.80237006891186\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics for train data\n",
    "print(\"test data: Decision Tree Accuracy Score -> \",accuracy_score(newsgroups_test.target, test_pred)*100)\n",
    "print(\"test data: Decision Tree precision Score -> \",precision_score(newsgroups_test.target, test_pred,average='macro')*100)\n",
    "print(\"test data: Decision Tree recall Score -> \",recall_score(newsgroups_test.target, test_pred,average='macro')*100)\n",
    "print(\"test data: Decision Tree f1 Score -> \",f1_score(newsgroups_test.target, test_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.40      0.16      0.23       319\n",
      "           comp.graphics       0.41      0.14      0.21       389\n",
      " comp.os.ms-windows.misc       0.45      0.61      0.52       394\n",
      "comp.sys.ibm.pc.hardware       0.23      0.34      0.28       392\n",
      "   comp.sys.mac.hardware       0.58      0.44      0.50       385\n",
      "          comp.windows.x       0.77      0.12      0.21       395\n",
      "            misc.forsale       0.72      0.59      0.65       390\n",
      "               rec.autos       0.79      0.53      0.63       396\n",
      "         rec.motorcycles       0.89      0.70      0.78       398\n",
      "      rec.sport.baseball       0.47      0.51      0.49       397\n",
      "        rec.sport.hockey       0.84      0.41      0.55       399\n",
      "               sci.crypt       0.76      0.59      0.66       396\n",
      "         sci.electronics       0.10      0.33      0.16       393\n",
      "                 sci.med       0.17      0.23      0.20       396\n",
      "               sci.space       0.55      0.63      0.59       394\n",
      "  soc.religion.christian       0.55      0.66      0.60       398\n",
      "      talk.politics.guns       0.53      0.41      0.46       364\n",
      "   talk.politics.mideast       0.85      0.55      0.66       376\n",
      "      talk.politics.misc       0.13      0.31      0.18       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "               micro avg       0.42      0.42      0.42      7532\n",
      "               macro avg       0.51      0.41      0.43      7532\n",
      "            weighted avg       0.52      0.42      0.44      7532\n",
      "\n",
      "Accuracy of the model= 0.4243228890069039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(newsgroups_test.target, test_pred, target_names=newsgroups_test.target_names))\n",
    "print(\"Accuracy of the model=\",metrics.accuracy_score(newsgroups_test.target, test_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Decision Tree does not perform well in this case as being a tree classification method it might need several nodes which can be hard to find for text classification problems. However, Decision trees perform well for structured data.\n",
    "\n",
    "Among various machine learning models Naive Bayes Classifier using TFIDF performs best closely followed by SGD Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
